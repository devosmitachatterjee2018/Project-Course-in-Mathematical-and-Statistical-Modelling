{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting x-y coordinates which only contain Straight path in '2017-04-28_00h_tracks.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                              Time        x        y\n",
      "138919  10016828  2017-04-28 07:50:30.946000+02:00  3.09921   9.8495\n",
      "138920  10016828  2017-04-28 07:50:31.198000+02:00  3.24182  9.89922\n",
      "138921  10016828  2017-04-28 07:50:31.451000+02:00  3.77567  10.2399\n",
      "138922  10016828  2017-04-28 07:50:31.704000+02:00  4.15824  10.5106\n",
      "138923  10016828  2017-04-28 07:50:31.959000+02:00  4.34589  10.6522\n",
      "Selected paths saved to csv !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#num_TOs = 1500\n",
    "x_left_bound = 5\n",
    "x_right_bound = 33\n",
    "y_upper_bound = -30\n",
    "y_lower_bound = 2\n",
    "\n",
    "x_condition_2 = 22\n",
    "y_condition_2 = -15\n",
    "theta = 0.523\n",
    "\n",
    "# Loading original tracks data:\n",
    "cols = ['ID','Time','x', 'y','Speed','Type','Estimated']\n",
    "data = pd.read_csv('2017-04-28_00h_tracks.csv',index_col=False, header=None,sep=';',names=cols )\n",
    "data = data.drop(data.index[0])   # drops the first row\n",
    "df1 = data[(data['Type'] == 2)]  # only selecting TO of type 2 (car)\n",
    "\n",
    "# rotate x-y-coordinates by theta to align the road with the x-y axis in the map:\n",
    "df1['x_rot'] = df1['x'].multiply(np.cos(theta)) - df1['y'].multiply(np.sin(theta))\n",
    "df1['y_rot'] = df1['x'].multiply(np.sin(theta)) + df1['y'].multiply(np.cos(theta))\n",
    "\n",
    "\n",
    "# creating new data frame for plotting trajectories: \n",
    "df = pd.DataFrame(columns=['ID', 'Time', 'x', 'y'])\n",
    "\n",
    "grouped = df1.groupby(['ID'])   # selecting only TO ID:s that fullfill x-y coord. condition for right turn\n",
    "for ID,group in grouped:\n",
    "\n",
    "    df_temp = pd.DataFrame({#'x_cond':group['x'].between(x_left_bound, x_right_bound),\n",
    "                            #'y_cond':group['y'].between(y_upper_bound, y_lower_bound),\n",
    "                            'x_cond2':[not(group['x'] > 18).any()]\n",
    "                            ,'x_cond3':[not(group['x'] <= -6).any()]\n",
    "                            ,'x_cond4':not(group['x_rot'] < 2).any()\n",
    "                            ,'x_cond5':not(group['x_rot'] > 7).any()        \n",
    "                            #,'y_cond2':(group['y'] < -15).any()\n",
    "                           })\n",
    "    \n",
    "    if df_temp.all(axis=None):   # if boundary conditions for x and y are fullfilled\n",
    "        df = df.append(group[['ID','Time','x_rot','y_rot']])\n",
    "df = df.rename(columns={\"x_rot\": \"x\", \"y_rot\": \"y\"})\n",
    "df = df.iloc[:,[0,1,3,5]]\n",
    "print(df.head())\n",
    "# path to to put saved file:\n",
    "path = r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S'\n",
    "\n",
    "# the file is currently named 'selected_path.csv':\n",
    "df.to_csv(os.path.join(path, r'xy_S_2017_04_28_filtered.csv'), index=False)\n",
    "\n",
    "print('Selected paths saved to csv !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting x-y coordinates which only contain Straight path (2)  in '2017-04-28_00h_tracks.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID           object\n",
      "Time         object\n",
      "x            object\n",
      "y            object\n",
      "Speed        object\n",
      "Type         object\n",
      "Estimated    object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-1c0de1b0a63c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     df_temp = pd.DataFrame({#'x_cond':group['x'].between(x_left_bound, x_right_bound),\n\u001b[0;32m     35\u001b[0m                             \u001b[1;31m#'y_cond':group['y'].between(y_upper_bound, y_lower_bound),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                             \u001b[1;34m'x_cond2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                             \u001b[1;33m,\u001b[0m\u001b[1;34m'x_cond3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                             \u001b[1;33m,\u001b[0m\u001b[1;34m'x_cond4'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_rot'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mlogical_func\u001b[1;34m(self, axis, bool_only, skipna, level, **kwargs)\u001b[0m\n\u001b[0;32m  11030\u001b[0m                                       skipna=skipna)\n\u001b[0;32m  11031\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[1;32m> 11032\u001b[1;33m                             numeric_only=bool_only, filter_type='bool')\n\u001b[0m\u001b[0;32m  11033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11034\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogical_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3628\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[0;32m   3629\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m         \u001b[1;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanany\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \"\"\"\n\u001b[0;32m    365\u001b[0m     values, mask, dtype, _, _ = _get_values(values, skipna, False, copy=skipna,\n\u001b[1;32m--> 366\u001b[1;33m                                             mask=mask)\n\u001b[0m\u001b[0;32m    367\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_get_values\u001b[1;34m(values, skipna, fill_value, fill_value_typ, isfinite, copy, mask)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_isfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_datetime_or_timedelta_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \"\"\"\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    112\u001b[0m                           \u001b[0mABCExtensionArray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                           ABCDatetimeArray, ABCTimedeltaArray)):\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;31m# box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#num_TOs = 1500\n",
    "x_left_bound = 5\n",
    "x_right_bound = 33\n",
    "y_upper_bound = -30\n",
    "y_lower_bound = 2\n",
    "\n",
    "x_condition_2 = 22\n",
    "y_condition_2 = -15\n",
    "theta = 1.047\n",
    "\n",
    "# Loading original tracks data:\n",
    "cols = ['ID','Time','x', 'y','Speed','Type','Estimated']\n",
    "data = pd.read_csv('2017-04-28_00h_tracks.csv',index_col=False, header=None,sep=';',names=cols )\n",
    "data = data.drop(data.index[0])   # drops the first row\n",
    "df1 = data[(data['Type'] == 2)]  # only selecting TO of type 2 (car)\n",
    "print(df1.dtypes)\n",
    "# rotate x-y-coordinates by theta to align the road with the x-y axis in the map:\n",
    "df1['x_rot'] = df1['x'].multiply(np.cos(theta)) - df1['y'].multiply(np.sin(theta))\n",
    "df1['y_rot'] = df1['x'].multiply(np.sin(theta)) + df1['y'].multiply(np.cos(theta))\n",
    "\n",
    "\n",
    "# creating new data frame for plotting trajectories: \n",
    "df = pd.DataFrame(columns=['ID', 'Time', 'x', 'y'])\n",
    "\n",
    "grouped = df1.groupby(['ID'])   # selecting only TO ID:s that fullfill x-y coord. condition for right turn\n",
    "for ID,group in grouped:\n",
    "\n",
    "    df_temp = pd.DataFrame({#'x_cond':group['x'].between(x_left_bound, x_right_bound),\n",
    "                            #'y_cond':group['y'].between(y_upper_bound, y_lower_bound),\n",
    "                            'x_cond2':[(group['x'] > 23).any()]\n",
    "                            ,'x_cond3':[(group['x'] <= -20).any()]\n",
    "                            ,'x_cond4':not(group['x_rot'] < -5).any()\n",
    "                            ,'x_cond5':not(group['x_rot'] > 5).any()        \n",
    "                            #,'y_cond2':(group['y'] < -15).any()\n",
    "                           })\n",
    "    \n",
    "    if df_temp.all(axis=None):   # if boundary conditions for x and y are fullfilled\n",
    "        df = df.append(group[['ID','Time','x','y']])\n",
    "#df = df.rename(columns={\"x_rot\": \"x\", \"y_rot\": \"y\"})\n",
    "#df = df.iloc[:,[0,1,3,5]]\n",
    "print(df.head())\n",
    "# path to to put saved file:\n",
    "path = r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S'\n",
    "\n",
    "# the file is currently named 'selected_path.csv':\n",
    "df.to_csv(os.path.join(path, r'xy_S2_2017_04_28_filtered.csv'), index=False)\n",
    "\n",
    "print('Selected paths saved to csv !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to lat-long coord :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\"\"\" Converts data x-y coordinates into latitudinal and longitudinal positions.\n",
    " Specify below the path where the csv file is to be saved. Requires Pandas and Numpy package.\"\"\"\n",
    "\n",
    "########################################################################################################################\n",
    "# lat <=> y, long <=> x\n",
    "ref_position = np.array([59.916559, 10.734520])\n",
    "lat = 59.916687\n",
    "lon = 10.734836\n",
    "position = [lat, lon]\n",
    "\n",
    "diff_lat = position[0] - ref_position[0]\n",
    "diff_lon = position[1] - ref_position[1]\n",
    "\n",
    "diff_x = 23.41\n",
    "diff_y = -20\n",
    "\n",
    "const_lat = np.round(diff_lat/diff_y, 6)\n",
    "const_lon = np.round(diff_lon/diff_x, 6)\n",
    "\n",
    "theta = np.pi + np.pi/2\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "cols = ['ID','Time','x', 'y']\n",
    "\n",
    "# Add the csv file to be converted here:\n",
    "df = pd.read_csv(r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S\\xy_S2_2017_04_28_filtered.csv', index_col=False, header=None, sep=',', names= cols)\n",
    "df = df.drop(df.index[0])   # drops the first row\n",
    "\n",
    "df['lat'] = df['y'].astype(float)\n",
    "df['long'] = df['x'].astype(float)\n",
    "df['x'] = df['long'].astype(float)\n",
    "df['y'] = df['lat'].astype(float)\n",
    "\n",
    "# rotate x-y-coordinates by pi/2:\n",
    "#df['x_new'] = df['x'].multiply(np.cos(theta)) - df['y'].multiply(np.sin(theta))\n",
    "#df['y_new'] = df['x'].multiply(np.sin(theta)) + df['y'].multiply(np.cos(theta))\n",
    "\n",
    "df['const_lat'] = const_lat\n",
    "df['const_long'] = const_lon\n",
    "df['ref_lat'] = ref_position[0]\n",
    "df['ref_long'] = ref_position[1]\n",
    "\n",
    "df['lat'] = df['y'].multiply(df['const_lat'])\n",
    "df['lat'] = df['lat'].add(df['ref_lat'])\n",
    "\n",
    "df['long'] = df['x'].multiply(df['const_long'])\n",
    "df['long'] = df['long'].add(df['ref_long'])\n",
    "\n",
    "#df = df.drop(['const_lat', 'const_long', 'ref_lat', 'ref_long', 'x', 'y', 'x_new', 'y_new'], axis=1)\n",
    "df = df.drop(['const_lat', 'const_long', 'ref_lat', 'ref_long', 'x', 'y'], axis=1)\n",
    "\n",
    "# rounding positions coordinates to 6 decimals:\n",
    "df = df.round({'lat': 6, 'long': 6})\n",
    "\n",
    "# path to to put saved file:\n",
    "path = r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S'\n",
    "\n",
    "# the file is currently named 'LatLongData.csv':\n",
    "df.to_csv(os.path.join(path, r'LatLongData_area_2017_04_28_S.csv'), index=False)\n",
    "\n",
    "print('conversion completed!')\n",
    "df_converted = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating geojson file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geojson created!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "''' This script converts the a data frame with columns: 'ID', 'lat', long' into geojson file for plotting '''\n",
    "\n",
    "########################################################################################################################\n",
    "'''\n",
    "# example data:    note: the 'lat' and 'long' must not be of typ numpy.int64 !\n",
    "Data = {'ID': [1, 1, 1, 1, 2, 2, 2, 2, 2, 2], 'lat':  [10.734221, 10.734474, 10.734661, 10.734940,  10.734114,\n",
    "                                                       10.734527, 10.734436, 10.734168, 10.733894, 10.733749],\n",
    "        'long': [59.916174, 59.916397, 59.916545, 59.916757,  59.916206, 59.916521, 59.916615, 59.916679, 59.916765,\n",
    "                 59.916798]\n",
    "        }\n",
    "df = DataFrame(Data, columns=['ID', 'lat', 'long'])\n",
    "\n",
    "'''\n",
    "########################################################################################################################\n",
    "cols = ['ID','Time','lat', 'long']\n",
    "# Add the csv file to be converted here:\n",
    "df = pd.read_csv(r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S\\LatLongData_area_2017_04_28_S.csv', index_col=False, header=None, sep=',', names=cols)\n",
    "df = df.drop(df.index[0])   # drops the first row\n",
    "del df['Time']\n",
    "#df = df.loc[:, ['ID', 'lat', 'long']]\n",
    "\n",
    "\n",
    "# choose number of traffic objects to plot:\n",
    "num_TO = 900\n",
    "TO_unique = df.ID.unique()\n",
    "batch = TO_unique[0:num_TO]\n",
    "df = df[df['ID'].isin(batch)]\n",
    "\n",
    "df['lat'] = df['lat'].astype(float)\n",
    "df['long'] = df['long'].astype(float)\n",
    "def df_to_geojson(df):\n",
    "    # extracting unique TO IDs:\n",
    "    TO_unique = df.ID.unique()\n",
    "    MultiLineString = []\n",
    "    for object in TO_unique:\n",
    "        # converts the the data frame to an array  [[ , ],[ , ],...[ , ]] :\n",
    "        string = df.loc[df['ID'] == object].values\n",
    "        # deleting first element in the array (corresponding to the ID value):\n",
    "        string = np.delete(string, np.s_[0], 1)\n",
    "        num_rows = len(string)\n",
    "        object_string = []\n",
    "        for row in range(num_rows):\n",
    "            string[row][0] = np.round(string[row][0], 6)\n",
    "            string[row][1] = np.round(string[row][1], 6)\n",
    "            object_string.append([string[row][1], string[row][0]])\n",
    "        MultiLineString.append(object_string)\n",
    "\n",
    "    geojson_dict = {'type': 'FeatureCollection', 'features': [{'type': 'Feature', 'properties': {}, 'geometry':\n",
    "        {'type':'MultiLineString', 'coordinates': MultiLineString}}]}\n",
    "\n",
    "    return geojson_dict\n",
    "\n",
    "geojson_dict = df_to_geojson(df)\n",
    "\n",
    "geojson_str = json.dumps(geojson_dict, indent=2)\n",
    "\n",
    "# save the geojson result to a file\n",
    "output_filename = 'TO_paths_2017_04_28_S2.geojson'\n",
    "\n",
    "\n",
    "#with open(output_filename, 'wb') as output_file:\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    output_file.write('{}'.format(geojson_str))\n",
    "\n",
    "print('geojson created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Straight paths from the file above that corresponds to the time interval calculated from the GridExtractor, also choosing the data from GridExtractor that matches with the file above  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected paths saved to csv !\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "coordinates for restricted area in 'result_L.csv' is : [[[-35,-20],[8,-20]],[[-35,20],[8,20]]]\n",
    "'''\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "# num_TOs = 1500\n",
    "\n",
    "# Loading file which contains x-y coord for right turn paths:\n",
    "\n",
    "data1 = pd.read_csv(r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S\\xy_S2_2017_04_28_filtered.csv')\n",
    "data1 = data1.drop(data1.index[0])   # drops the first row\n",
    "#df1 = data1[(data1['Type'] == 2)]  # only selecting TO of type 2 (car), allready filltered out above\n",
    "df1 = data1\n",
    "df1['Time'] = pd.to_datetime(df1['Time']) \n",
    "df1['Time'] = df1['Time'].astype('datetime64[ns]')\n",
    "df1['ID'] = df1['ID'].astype('int32')\n",
    "df1['ID'] = pd.to_numeric(df1['ID'])\n",
    "\n",
    "# Loading data with occupancy grid:\n",
    "data2 = pd.read_csv('result_2017_04_28_R_large.csv')\n",
    "data2['ID'] = data2['Object id']\n",
    "del data2['Object id']\n",
    "del data2['State time']\n",
    "\n",
    "# choosing random TO IDs in df2:\n",
    "#TO_unique = df2.ID.unique()\n",
    "#rand_ID = np.random.choice(TO_unique, num_TOs, replace=False)\n",
    "#df2 = df2.loc[df2['ID'].isin(rand_ID)]\n",
    "\n",
    "# choosing ID:s in df2 that also exists in df1:\n",
    "df2 = data2.loc[data2['ID'].isin(df1['ID'])]\n",
    "df2['ID'] = df2['ID'].astype('int32')\n",
    "#print(df2.dtypes)\n",
    "# choosing ID:s in df1 that is also existing in df2:\n",
    "df1 = df1.loc[df1['ID'].isin(df2['ID'])]\n",
    "\n",
    "# check if they have identical ID:s:\n",
    "#ID_df1 = df1.ID.unique()\n",
    "#ID_df2 = df2.ID.unique()\n",
    "#ID_df1 = np.sort(ID_df1, axis=None)\n",
    "#ID_df2 = np.sort(ID_df2, axis=None)\n",
    "#print(np.array_equal(ID_df1, ID_df2))\n",
    "\n",
    "\n",
    "# calculating state time for data containing occupancy grid:\n",
    "df2['Time id'] = df2['Time id'].astype(float)\n",
    "start_time = pd.to_datetime('2017-04-28 00:23:04.376') \n",
    "df2['State time'] = start_time + timedelta(seconds=0.3)*df2['Time id'] - timedelta(hours=2) - timedelta(seconds=5.5)\n",
    "\n",
    "\n",
    "#df2['Time_id_unique'] = (df2['Time id'].diff() != 1).cumsum()  # rows with consequtive increasing values gets same index\n",
    "\n",
    "\n",
    "# creating new data frame for plotting trajectories in map: \n",
    "df = pd.DataFrame(columns=['ID', 'Time', 'x', 'y'])\n",
    "\n",
    "# creating empty data frame for state vector:\n",
    "df_state = pd.DataFrame()\n",
    "\n",
    "# selecting x-y data that corresponds to the output from GridExtractor (for visualization of tracks in map)\n",
    "# also selecting the corresponding state vectors stored in df_state for clustering:\n",
    "grouped = df2.groupby(['ID'])  \n",
    "for ID,group in grouped:\n",
    "    df_temp = df1.loc[df1['ID'] == ID, ['ID', 'Time', 'x', 'y']]\n",
    "    df_temp = df_temp[(df_temp['Time'] >= group['State time'].iloc[0]) & (df_temp['Time'] <= group['State time'].iloc[-1])]\n",
    "    if len(df_temp.index) > 10:    # only using ID:s containing more than 30 data points\n",
    "        df = df.append(df_temp)\n",
    "        df_state = df_state.append(group)\n",
    "\n",
    "# path to to put saved file:\n",
    "path = r'C:\\Users\\Desktop\\CAS\\Project_course_math_stat_modelling\\2017_04_28_S'\n",
    "\n",
    "# the file is currently named 'xy_right_time_matching.csv':\n",
    "df.to_csv(os.path.join(path, r'xy_S2_2017_04_28_filtered.csv'), index=False)\n",
    "\n",
    "# the file is currently named 'state_vector_left_turn.csv':\n",
    "df_state.to_csv(os.path.join(path, r'state_vect_S2_2017_04_28.csv'), index=False)\n",
    "\n",
    "print('Selected paths saved to csv !')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
